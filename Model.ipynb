{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import sklearn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "import PIL\n",
    "import sys, os\n",
    "from sklearn.decomposition import SparseCoder\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numInputs = 192\n",
    "batchSize = 16\n",
    "numImages = 100\n",
    "IMAGE_SIZE = (32,32,3)\n",
    "IMAGE_FILE = \"./test_batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec2RGB(images, i=-1,dim=32):\n",
    "  if i != -1:\n",
    "    img = np.copy(images[i])\n",
    "  else:\n",
    "    img = images\n",
    "  n = int(len(img) / 3)\n",
    "  red = img[0:n]\n",
    "  green = img[n:2 * n]\n",
    "  blue = img[2 * n:3 * n]\n",
    "  img = np.zeros((dim**2, 3))\n",
    "  for i in range(len(red)):\n",
    "    img[i, 0] = int(red[i])\n",
    "    img[i, 1] = int(green[i])\n",
    "    img[i, 2] = int(blue[i])\n",
    "  img = np.reshape(img, (dim, dim, 3))\n",
    "  return img.astype(int)\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def fullImage2Patches(image):\n",
    "    # Make batch of random image\n",
    "    patches = np.zeros((numInputs, batchSize))  # getting sequential 8x8 RGB patches (192 pixels each)\n",
    "    red = np.reshape(image[0:1024],(32,32))\n",
    "    green = np.reshape(image[1024:2048],(32,32))\n",
    "    blue = np.reshape(image[2048:3072],(32,32))\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            red_layer = red[0 +8 *i:8 + 8*i,0 + 8*j:8 + 8*j].flatten()\n",
    "            green_layer = green[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            blue_layer = blue[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            patches[:,i*4+j] = np.concatenate((red_layer,green_layer,blue_layer))\n",
    "\n",
    "\n",
    "    return patches\n",
    "\n",
    "def patches2FullImage(patches):\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for patch_id in range(len(patches[0])): # for each patch\n",
    "        patch = patches[:,patch_id]\n",
    "        red_layer = np.reshape(patch[0:64],(8,8))\n",
    "        green_layer = np.reshape(patch[64:128],(8,8))\n",
    "        blue_layer = np.reshape(patch[128:192],(8,8))\n",
    "        if len(red)==0:\n",
    "            red = red_layer\n",
    "            green = green_layer\n",
    "            blue = blue_layer\n",
    "        else:\n",
    "            red = np.concatenate((red,red_layer),axis=1)\n",
    "            green = np.concatenate((green,green_layer),axis=1)\n",
    "            blue = np.concatenate((blue,blue_layer),axis=1)\n",
    "    i = 0\n",
    "    offset = i*32\n",
    "    red_layer = np.concatenate((red[:,0+offset:32+offset],red[:,32+offset:64+offset],red[:,64+offset:96+offset],red[:,96+offset:128+offset]),axis=0)\n",
    "    green_layer = np.concatenate((green[:,0 + offset:32], green[:,32 + offset:64], green[:,64 + offset:96], green[:,96 + offset:128]),axis=0)\n",
    "    blue_layer = np.concatenate((blue[:,0 + offset:32], blue[:,32 + offset:64], blue[:,64 + offset:96], blue[:,96 + offset:128]),axis=0)\n",
    "\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for i in range(len(red_layer)):\n",
    "        red = np.concatenate((red,red_layer[i,:]))\n",
    "        green = np.concatenate((green, green_layer[i, :]))\n",
    "        blue = np.concatenate((blue, blue_layer[i, :]))\n",
    "\n",
    "    reconstruction = np.concatenate((red,green,blue))\n",
    "    return reconstruction\n",
    "\n",
    "def get_cifar_data():\n",
    "    dict = unpickle(IMAGE_FILE)\n",
    "    return dict[b'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./dictionary\",\"rb\")\n",
    "dict = np.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_cifar_data()[0:numImages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sparse Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_patches = []\n",
    "sparse_codes = []\n",
    "sparse_codes_flattened = []\n",
    "\n",
    "for i in range(numImages):\n",
    "    patches = fullImage2Patches(images[i])\n",
    "    all_patches.append(patches)\n",
    "    coder = SparseCoder(dict.T,transform_algorithm='lasso_lars',positive_code=True)\n",
    "    sc = coder.transform(patches.T)\n",
    "    sparse_codes.append(sc)\n",
    "    sparse_codes_flattened.append(sc.flatten())\n",
    "\n",
    "all_patches = np.array(all_patches)\n",
    "sparse_codes = np.array(sparse_codes)\n",
    "sparse_codes_flattened = np.array(sparse_codes_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3072)\n",
      "(100, 192, 16)\n",
      "3072 = 192 * 16\n",
      "(100, 1024)\n",
      "(100, 16, 64)\n",
      "1024 = 16 * 64\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(all_patches.shape)\n",
    "print(\"{} = {} * {}\".format(all_patches.shape[1] * all_patches.shape[2], all_patches.shape[1], all_patches.shape[2]))\n",
    "print(sparse_codes_flattened.shape)\n",
    "print(sparse_codes.shape)\n",
    "print(\"{} = {} * {}\".format(sparse_codes.shape[1] * sparse_codes.shape[2], sparse_codes.shape[1], sparse_codes.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(img_dim, sparse_code_dim):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential: compiled genrator model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, input_shape=(img_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(1204, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(sparse_code_dim, activation=tf.keras.layers.ReLU()))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(sparse_code_dim):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential: compiled discriminator model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(512, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(128, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(64, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(32, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(1, input_shape=(sparse_code_dim,), activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        discriminator (keras.engine.sequential.Sequential): compiled discriminator model\n",
    "        generator (keras.engine.sequential.Sequential): compilted generator model\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential : compiled GAN model,\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    discriminator.trainable = False\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(images, true_sparse_codes, epochs=200, batch_size=100):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        epochs (int): amount of training iterations\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential, keras.engine.sequential.Sequential: trained generator and discriminator\n",
    "\n",
    "    \"\"\"\n",
    "    generator = get_generator(images.shape[1], true_sparse_codes.shape[1])\n",
    "    discriminator = get_discriminator(true_sparse_codes.shape[1])\n",
    "    gan = make_gan(generator, discriminator)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # Get real sparse codes\n",
    "        real_z = true_sparse_codes\n",
    "\n",
    "        # Predict sparse codes with images\n",
    "        false_z = generator.predict(images)\n",
    "\n",
    "        # Construct batch\n",
    "        batch = np.concatenate((real_z, false_z))\n",
    "\n",
    "        # Initialize output\n",
    "        y = np.concatenate((np.ones(batch_size), np.zeros(batch_size)))\n",
    "\n",
    "        # Train discriminator\n",
    "        accuracy = discriminator.train_on_batch(batch, y)\n",
    "\n",
    "        # Train generator\n",
    "        history = gan.train_on_batch(images, np.ones(batch_size))\n",
    "\n",
    "    return generator, discriminator, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator, history = train(images, sparse_codes_flattened, epochs=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "generator_json = generator.to_json()\n",
    "with open(\"generator.json\", \"w\") as json_file:\n",
    "    json_file.write(generator_json)\n",
    "# serialize weights to HDF5\n",
    "generator.save_weights(\"generator.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# serialize model to JSON\n",
    "discriminator_json = discriminator.to_json()\n",
    "with open(\"discriminator.json\", \"w\") as json_file:\n",
    "    json_file.write(discriminator_json)\n",
    "# serialize weights to HDF5\n",
    "discriminator.save_weights(\"discriminator.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# # later...\n",
    " \n",
    "# # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('history.npy', np.array(history))\n",
    "np.save('history.l', history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = generator.predict(images)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_distances = []\n",
    "cosine_distances = []\n",
    "mutual_info = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    hamming = np.count_nonzero(preds[i] == sparse_codes_flattened[i])\n",
    "    cosine = spatial.distance.cosine(preds[i], sparse_codes_flattened[i])\n",
    "    mut = sklearn.metrics.mutual_info_score(preds[i], sparse_codes_flattened[i])\n",
    "\n",
    "hamming_distances.append(hamming)\n",
    "cosine_distances.append(cosine)\n",
    "mutual_info.append(mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.average(hamming_distances)/1024)\n",
    "print(np.average(cosine_distances))\n",
    "print(np.average(mutual_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc0 = preds[0].reshape(16, 64)\n",
    "print(sc0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patches_reconstructed = dict @ sc0.T\n",
    "print(patches_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reconstruction = patches2FullImage(patches_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(reconstruction.shape)\n",
    "reco = vec2RGB(reconstruction)\n",
    "print(reco.shape)\n",
    "plt.imshow(reco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sparse_codes = np.array(sparse_codes)\n",
    "sparse_codes_flattened = np.array(sparse_codes_flattened)\n",
    "print(dict.shape)\n",
    "\n",
    "r = sparse_codes[1] @ dict.T\n",
    "# r = np.dot(sparse_codes[0], dict.T)\n",
    "r2 = patches2FullImage(r.T)\n",
    "# r3 = r2.reshape(3, 32, 32).T\n",
    "# r3 = r2.reshape(32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(all_patches[0].shape)\n",
    "a = sparse_codes[0] @ dict.T\n",
    "# print(np.count_zero(a == all_patches[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sc0 = preds[0].reshape(16, 64)\n",
    "print(sc0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_reconstructed = dict @ sc0.T\n",
    "print(patches_reconstructed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = patches2FullImage(patches_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = vec2RGB(reconstruction)\n",
    "print(reco.shape)\n",
    "plt.imshow(reco)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_codes = np.array(sparse_codes)\n",
    "sparse_codes_flattened = np.array(sparse_codes_flattened)\n",
    "\n",
    "print(sparse_codes[1].shape)\n",
    "print(dict.shape)\n",
    "\n",
    "# r = sparse_codes[1] @ dict.T\n",
    "# r = np.dot(sparse_codes[0], dict.T)\n",
    "# print(r.shape)\n",
    "# r2 = patches2FullImage(r.T)\n",
    "# print(r2.shape)\n",
    "\n",
    "# plt.imshow(vec2RGB(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_patches[0].shape)\n",
    "a = sparse_codes[0] @ dict.T\n",
    "# print(np.count_zero(a == all_patches[0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "true = vec2RGB(patches2FullImage(a.T))\n",
    "plt.imshow(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "# !pip install keras\n",
     "# !pip install tensorflow\n",
     "# !pip install scipy\n",
     "# !pip install sklearn\n",
     "# !pip install pillow"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
