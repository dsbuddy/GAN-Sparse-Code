{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import sys, os\n",
    "from sklearn.decomposition import sparse_encode\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numInputs = 192\n",
    "batchSize = 16\n",
    "IMAGE_SIZE = (32,32,3)\n",
    "IMAGE_FILE = \"test_batch\"\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def fullImage2Patches(image):\n",
    "    # Make batch of random image\n",
    "    patches = np.zeros((numInputs, batchSize))  # getting sequential 8x8 RGB patches (192 pixels each)\n",
    "    red = np.reshape(image[0:1024],(32,32))\n",
    "    green = np.reshape(image[1024:2048],(32,32))\n",
    "    blue = np.reshape(image[2048:3072],(32,32))\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            red_layer = red[0 +8 *i:8 + 8*i,0 + 8*j:8 + 8*j].flatten()\n",
    "            green_layer = green[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            blue_layer = blue[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            patches[:,i*4+j] = np.concatenate((red_layer,green_layer,blue_layer))\n",
    "\n",
    "\n",
    "    return patches\n",
    "\n",
    "def patches2FullImage(patches):\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for patch_id in range(len(patches[0])): # for each patch\n",
    "        patch = patches[:,patch_id]\n",
    "        red_layer = np.reshape(patch[0:64],(8,8))\n",
    "        green_layer = np.reshape(patch[64:128],(8,8))\n",
    "        blue_layer = np.reshape(patch[128:192],(8,8))\n",
    "        if len(red)==0:\n",
    "            red = red_layer\n",
    "            green = green_layer\n",
    "            blue = blue_layer\n",
    "        else:\n",
    "            red = np.concatenate((red,red_layer),axis=1)\n",
    "            green = np.concatenate((green,green_layer),axis=1)\n",
    "            blue = np.concatenate((blue,blue_layer),axis=1)\n",
    "    i = 0\n",
    "    offset = i*32\n",
    "    red_layer = np.concatenate((red[:,0+offset:32+offset],red[:,32+offset:64+offset],red[:,64+offset:96+offset],red[:,96+offset:128+offset]),axis=0)\n",
    "    green_layer = np.concatenate((green[:,0 + offset:32], green[:,32 + offset:64], green[:,64 + offset:96], green[:,96 + offset:128]),axis=0)\n",
    "    blue_layer = np.concatenate((blue[:,0 + offset:32], blue[:,32 + offset:64], blue[:,64 + offset:96], blue[:,96 + offset:128]),axis=0)\n",
    "\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for i in range(len(red_layer)):\n",
    "        red = np.concatenate((red,red_layer[i,:]))\n",
    "        green = np.concatenate((green, green_layer[i, :]))\n",
    "        blue = np.concatenate((blue, blue_layer[i, :]))\n",
    "\n",
    "    reconstruction = np.concatenate((red,green,blue))\n",
    "    return reconstruction\n",
    "\n",
    "def get_cifar_data():\n",
    "    dict = unpickle(IMAGE_FILE)\n",
    "    return dict[b'data']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"dictionary\",\"rb\")\n",
    "dict = np.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_cifar_data()[0:100]\n",
    "sparse_codes = []\n",
    "all_patches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    patches = fullImage2Patches(images[i])\n",
    "    all_patches.append(patches)\n",
    "    sparse_codes.append(sparse_encode(patches.T,dict.T,algorithm=\"threshold\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 64)\n",
      "(1024,)\n",
      "(16, 64)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sc = sparse_codes[0]\n",
    "print(sc.shape)\n",
    "sc_flat = sc.flatten()\n",
    "print(sc_flat.shape)\n",
    "sc_r = sc.reshape(16, 64)\n",
    "print(sc_r.shape)\n",
    "print(np.all(sc_r == sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "np.save('new_sparse_codes.npy', sparse_codes)\n",
    "l = np.load('new_sparse_codes.npy')\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"new_sparse_codes\",\"wb\")\n",
    "np.save(file, sparse_codes)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
