{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import sklearn\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import Adam\n",
    "import PIL\n",
    "import sys, os\n",
    "from sklearn.decomposition import sparse_encode\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numInputs = 192\n",
    "batchSize = 16\n",
    "numImages = 100\n",
    "IMAGE_SIZE = (32,32,3)\n",
    "IMAGE_FILE = \"test_batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def fullImage2Patches(image):\n",
    "    # Make batch of random image\n",
    "    patches = np.zeros((numInputs, batchSize))  # getting sequential 8x8 RGB patches (192 pixels each)\n",
    "    red = np.reshape(image[0:1024],(32,32))\n",
    "    green = np.reshape(image[1024:2048],(32,32))\n",
    "    blue = np.reshape(image[2048:3072],(32,32))\n",
    "\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            red_layer = red[0 +8 *i:8 + 8*i,0 + 8*j:8 + 8*j].flatten()\n",
    "            green_layer = green[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            blue_layer = blue[0 + 8*i:8 + 8*i, 0 + 8*j:8 + 8*j].flatten()\n",
    "            patches[:,i*4+j] = np.concatenate((red_layer,green_layer,blue_layer))\n",
    "\n",
    "\n",
    "    return patches\n",
    "\n",
    "def patches2FullImage(patches):\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for patch_id in range(len(patches[0])): # for each patch\n",
    "        patch = patches[:,patch_id]\n",
    "        red_layer = np.reshape(patch[0:64],(8,8))\n",
    "        green_layer = np.reshape(patch[64:128],(8,8))\n",
    "        blue_layer = np.reshape(patch[128:192],(8,8))\n",
    "        if len(red)==0:\n",
    "            red = red_layer\n",
    "            green = green_layer\n",
    "            blue = blue_layer\n",
    "        else:\n",
    "            red = np.concatenate((red,red_layer),axis=1)\n",
    "            green = np.concatenate((green,green_layer),axis=1)\n",
    "            blue = np.concatenate((blue,blue_layer),axis=1)\n",
    "    i = 0\n",
    "    offset = i*32\n",
    "    red_layer = np.concatenate((red[:,0+offset:32+offset],red[:,32+offset:64+offset],red[:,64+offset:96+offset],red[:,96+offset:128+offset]),axis=0)\n",
    "    green_layer = np.concatenate((green[:,0 + offset:32], green[:,32 + offset:64], green[:,64 + offset:96], green[:,96 + offset:128]),axis=0)\n",
    "    blue_layer = np.concatenate((blue[:,0 + offset:32], blue[:,32 + offset:64], blue[:,64 + offset:96], blue[:,96 + offset:128]),axis=0)\n",
    "\n",
    "    red = []\n",
    "    green = []\n",
    "    blue = []\n",
    "    for i in range(len(red_layer)):\n",
    "        red = np.concatenate((red,red_layer[i,:]))\n",
    "        green = np.concatenate((green, green_layer[i, :]))\n",
    "        blue = np.concatenate((blue, blue_layer[i, :]))\n",
    "\n",
    "    reconstruction = np.concatenate((red,green,blue))\n",
    "    return reconstruction\n",
    "\n",
    "def get_cifar_data():\n",
    "    dict = unpickle(IMAGE_FILE)\n",
    "    return dict[b'data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"dictionary\",\"rb\")\n",
    "dict = np.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_cifar_data()[0:numImages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sparse Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches = []\n",
    "sparse_codes = []\n",
    "sparse_codes_flattened = []\n",
    "\n",
    "for i in range(numImages):\n",
    "    patches = fullImage2Patches(images[i])\n",
    "    all_patches.append(patches)\n",
    "    sc = sparse_encode(patches.T,dict.T,algorithm=\"threshold\", positive=True)\n",
    "    sparse_codes.append(sc)\n",
    "    sparse_codes_flattened.append(sc.flatten())\n",
    "\n",
    "all_patches = np.array(all_patches)\n",
    "sparse_codes = np.array(sparse_codes)\n",
    "sparse_codes_flattened = np.array(sparse_codes_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3072)\n",
      "(100, 192, 16)\n",
      "3072 = 192 * 16\n",
      "(100, 1024)\n",
      "(100, 16, 64)\n",
      "1024 = 16 * 64\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(all_patches.shape)\n",
    "print(\"{} = {} * {}\".format(all_patches.shape[1] * all_patches.shape[2], all_patches.shape[1], all_patches.shape[2]))\n",
    "print(sparse_codes_flattened.shape)\n",
    "print(sparse_codes.shape)\n",
    "print(\"{} = {} * {}\".format(sparse_codes.shape[1] * sparse_codes.shape[2], sparse_codes.shape[1], sparse_codes.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(img_dim, sparse_code_dim):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential: compiled genrator model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, input_shape=(img_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(1204, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(128, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(sparse_code_dim, activation=tf.keras.layers.ReLU()))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(sparse_code_dim):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential: compiled discriminator model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(512, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(256, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(128, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(64, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(32, input_shape=(sparse_code_dim,), activation=tf.keras.layers.ReLU()))\n",
    "    model.add(tf.keras.layers.Dense(1, input_shape=(sparse_code_dim,), activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gan(generator, discriminator):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        discriminator (keras.engine.sequential.Sequential): compiled discriminator model\n",
    "        generator (keras.engine.sequential.Sequential): compilted generator model\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential : compiled GAN model, \n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    discriminator.trainable = False\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(images, true_sparse_codes, epochs=200, batch_size=100):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        epochs (int): amount of training iterations\n",
    "    Returns:\n",
    "        keras.engine.sequential.Sequential, keras.engine.sequential.Sequential: trained generator and discriminator\n",
    "    \n",
    "    \"\"\"\n",
    "    generator = get_generator(images.shape[1], true_sparse_codes.shape[1])\n",
    "    discriminator = get_discriminator(true_sparse_codes.shape[1])\n",
    "    gan = make_gan(generator, discriminator)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        # Get real sparse codes\n",
    "        real_z = true_sparse_codes\n",
    "        \n",
    "        # Predict sparse codes with images\n",
    "        false_z = generator.predict(images)\n",
    "\n",
    "        # Construct batch\n",
    "        batch = np.concatenate((real_z, false_z))\n",
    "\n",
    "        # Initialize output\n",
    "        y = np.concatenate((np.ones(batch_size), np.zeros(batch_size)))\n",
    "\n",
    "        # Train discriminator\n",
    "        accuracy = discriminator.train_on_batch(batch, y)\n",
    "\n",
    "        # Train generator\n",
    "        gan.train_on_batch(images, np.ones(batch_size))\n",
    "\n",
    "    return generator, discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, discriminator = train(images, sparse_codes_flattened, epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1024)\n"
     ]
    }
   ],
   "source": [
    "preds = generator.predict(images)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_distances = []\n",
    "cosine_distances = []\n",
    "mutual_info = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    hamming = np.count_nonzero(preds[i] == sparse_codes_flattened[i])\n",
    "    cosine = spatial.distance.cosine(preds[i], sparse_codes_flattened[i])\n",
    "    mut = sklearn.metrics.mutual_info_score(preds[i], sparse_codes_flattened[i])\n",
    "    \n",
    "hamming_distances.append(hamming)\n",
    "cosine_distances.append(cosine)\n",
    "mutual_info.append(mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603515625\n",
      "0.5090439304350995\n",
      "0.8382429896869648\n"
     ]
    }
   ],
   "source": [
    "print(np.average(hamming_distances)/1024)\n",
    "print(np.average(cosine_distances))\n",
    "print(np.average(mutual_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
